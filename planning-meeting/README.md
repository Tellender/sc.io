# Planning Meeting

First open neuroscience meeting:
 - 25th May 2018

### Goals:
 - Gathering individual researchers and groups that are already using, or intend to use in the short-term, open science workflows to collaborate and share in an ongoing fashion, all scientific outputs (e.g. raw data, analysis code, documentation, and manuscripts);
 - Document our process of collaboration: 
   - We are setting up this initiative to help our local network of scientists use open science workflows more easily. 
   - We want to document this process so that other people wishing to make this initial step for their local network of scientists have a starting point
   - Target audience: researchers that also have greater than average familiarity and comfort using online collaboration tools and with programming in general;
 - Compare individual experiences (successes and failures), methods (techniques and workflows), and skill sets;
 - Discuss possible standards to facilitate exchange and collaboration;
 - Discuss how to make our process more accessible to life scientists who may not be so familiar or comfortable with online tools and programming (lower the entry barrier).
 
### Structure:
 - Brief introduction by each participant, saying who they are, sharing experiences, methods, etc.
 - Short round-tables, discussion, on different parts of the scientific collaboration pipeline:
   - Hosting and validating raw data (DOI, MD5 checksum)
   - Reproducibility and provenance of analysis code and intermediate outputs (datasets, figures) - how do we track the who, what, when, where, how and why for scientific outputs
   - Strategies for reporting non-digital contributions (behavior annotations, surgeries, running animals, etc);
   - Can this pipeline be extended to other aspects of the scientific social infrastructure (e.g. facilities, administration, institutional culture, etc);
 - Scientific publishing pipeline:
   - Manuscripts as living documents
   - Continuous, transparent peer-review as pull-requests
   - How to use provenance for better credit assignment (dynamic metrics for credit assignment - can we avoid weighing everyone in the same scale?)
   - Explicitly stating intended audience (or providing ways of slicing the publication into multiple target audiences)
 - Negative and exploratory results:
   - Registered reports (stating what and how experiments will be done and getting preliminary feedback)
   - Transparent reporting (report all outputs of your work, regardless of perceived quality)
   - Cultivating the habit of explaining negative results
